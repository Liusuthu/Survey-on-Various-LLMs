# Attention Is All You Need—注解

### 一、模型结构

模型的overview如下：

<img src="./assets/transformer.png" style="zoom: 25%;" >

大部分用于序列转换(sequence transduction)的模型通常都由一个编码器(Encoder)和一个解码器(Decoder)组成，Transformer也遵从了这种设计。简单来讲，编码器可以将符号表示的输入序列$'\mathbf x=(x_1,\cdots,x_n)'$映射为表征(representation)序列$'\mathbf z=(z_1,\cdots,z_n)'$。当给定了表征序列后，解码器可以可以生成符号输出序列$'\mathbf y=(y_1,\cdots,y_m)'$，其中每个时刻解码器可以生成一个字符$y_i$，并且其总是自回归的，使用先前生成的符号作为额外输入。



#### 1、编码器

下图所示即为Transformer的编码器的一层(layer)，整个编码器是由$N$层(stack)堆叠而成的。

<img src="./assets/encoder.png" alt="image-20240606200814040" style="zoom:50%;" />

在编码器的每个层中，包含两个子层(sub-layer)，首先是一个多头自注意力(Multi-head self-attention)层，然后是一个简单的、位置上完全连接的前馈神经网络(FNN)层。可以看见每个子层都引入了残差连接，正如侧边由输入直接导向输出的箭头所示。每层的最后都会进行一次层归一化。

*注：各种归一化的比较如下图所示。*

<img src="./assets/norm.png" alt="image-20240606201446398" style="zoom:50%;" />

在Transformer编码器和解码器的每一个子层（sub-layer）最后引入层归一化（Layer Normalization）有以下几个好处：

1. **稳定训练过程**：层归一化通过标准化每一层的输入，减少了梯度爆炸和梯度消失问题，从而使得训练过程更加稳定和高效。
2. **加速收敛**：层归一化可以使模型的收敛速度加快，因为它能够确保每一层的输入分布更加一致，减少了模型训练中由于不同层输入分布变化带来的不稳定。
3. **提高模型性能**：通过标准化每一层的输入，层归一化有助于提高模型的整体性能，使其在训练集和测试集上的表现更加一致，避免过拟合或欠拟合。
4. **减少超参数调节**：层归一化使得模型对不同超参数（如学习率）的选择不那么敏感，从而减少了调节超参数的复杂度。
5. **更好的梯度传播**：在深层网络中，梯度传播往往会变得困难。层归一化可以在一定程度上缓解这个问题，使得梯度在反向传播过程中能够更有效地传递。

因此，编码器中每个子层的数学表示式可以写为：
$$
\text{Sub-layer Output}=\text{LayerNorm}(x+\text{Sublayer}(x))
$$
其中$\text{Sublayer}(x)$可以是多头自注意力计算，也可以是FNN计算。

在编码器中，为了规范向量维度进行残差连接等，模型中的所有子层和嵌入层(Embedding Layers)的输出维度都规范为$d_{model}$





#### 2、解码器

下图所示即为Transformer的解码器的一层(layer)，整个编码器是由$N$层(stack)堆叠而成的。

<img src="./assets/decoder.png" alt="image-20240606203520034" style="zoom:50%;" />

与编码器类似，在解码器的每个层中，包含三个子层(sub-layer)，除了前面提到过的多头自注意力层和FNN层外，还有一个多头注意力层，其输入是编码器的输出与上一个子层的输出（参见中间的子层，左边延伸过来的箭头便是编码器的输出）。可以看见每个子层都引入了残差连接，正如侧边由输入直接导向输出的箭头所示。每层的最后都会进行一次层归一化(Layer normalization)。

值得注意的是，编码器的第一个子层是一个带掩码的多头注意力层，这可以保证解码器只能看到当前时刻以前的信息，确保它是自回归(auto-agressive)的。该子层的输入是模型的输出经过Embedding与位置编码后的向量。

*注：Transformer的编码器和解码器有N层，每层都遵循这样的结构。*

==问：编码器和解码器对应的Layer之间进行连接吗？所以一共有N个编解码器之间的连接吗？==





#### 3、注意力机制

注意力机制的函数可以将查询(query)和键值对(key-value pairs)映射成输出向量。

##### （1）缩放点积注意力(Scaled Dot-Product Attention)

<img src="./assets/scaleddp.png" alt="image-20240606210709807" style="zoom: 67%;" />

如图所示，输入Q(query)与K(key)的维度为$d_k$，输入V(values)的维度为$d_v$，注意力的计算公式如下：
$$
\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
$$
在这里，QKV为矩阵，这是Transformer优异的可并行计算性质的体现，我们可以同时对大量的qkv进行计算，因此可以将他们并列为一个矩阵同时运算。

注意到softmax内部除了一个$\sqrt{d_k}$因子，这是因为在$d_k$较大时，矩阵乘积也会很大，会带来负面的效应，因此要进行缩放。根据softmax函数公式：
$$
\text{softmax}(x_i)=\frac{e^{x_i}}{\sum_j e^{x_j}}
$$
如果输入值（即点积得分）非常大，那么在计算指数项时也会非常大导致一个数值远远大于其他数值，从而使得软最大函数的梯度变得非常小，接近于零。这会影响梯度下降算法的有效性，使模型训练变得困难。通过对点积进行缩放，可以确保点积得分的分布更均匀，避免极端值。这样，软最大函数可以更有效地分配权重，模型的训练过程也变得更加稳定。



注：在这里的运算中，各个矩阵的尺寸为
$$
Q:B×L×d_k\\K:B×L×d_k\\V:B×L×d_v\\ \text{Attention Output}:B×L×d_v
$$




##### （2）多头注意力(Multi-head Attention)

如果将QKV一次性输入一个缩放点积注意力中进行运算，可能会由于平均注意力加权而降低模型的分辨率性能。在这里采用了多头注意力，可以从很多方面提升模型的性能。多头注意力的运算结构如下：

<img src="./assets/multihead.png" alt="image-20240606214851625" style="zoom:50%;" />

其计算数学表达式如下：
$$
\text{MultiHead}(Q,K,V)=\text{Concat}(\text{head}_1,\cdots,\text{head}_h)W^O\\
\text{h}_i=\text{Attention}(QW^Q_i,KW^K_i,VW^V_i)
$$
这里的各个W矩阵是<u>可学习</u>的线性投影矩阵，能将QKV映射到不同的空间上进行注意力运算，学习到更丰富的表示。h是头数。

各个矩阵的尺寸为：
$$
Q:B×L×d_{model}\\K:B×L×d_{model}\\V:B×L×d_{model}\\W_i^Q:d_{model}×d_k\\W_i^K:d_{model}×d_k\\W_i^V:d_{model}×d_v\\h_i:B×L×d_v\\\text{Concat Output: }B×L×hd_v\\W^O:hd_v×d_{model}\\\text{MultiHead Output:}B×L×d_{model}
$$
（注意这里的QKV和上面的不同，这里的QKV是更原始一些的数据，处理后的尺寸与上面的QKV相同）

根据结果可以发现，多头注意力输出的结果和输入的KQV(当L不同时尤其是Q)相同。





重点注意：QKV实际上是对同一个输入X通过不同的线性层映射得到的





##### *详细介绍矩阵的具体维度

矩阵具体维度参考：[图解 transformer——多头注意力（3） 作者：Ketan Doshi翻译：Afunby这是关于图解 transformer 系列的第三篇译文。该系列文章由 Ke... - 雪球 (xueqiu.com)](https://xueqiu.com/3993902801/284754798)

<img src="./assets/qkv.jpg" style="zoom: 80%;" >



#### 4、全连接前馈神经网络

全连接前馈神经网络(FFN)由一个ReLU激活函数和两个线性变换层组成，表达式如下所示：
$$
\text{FFN}(x)=\text{max}(0,xW_1+b_1)W_2+b_2
$$
尽管线性变换在不同位置上的操作是相同的，但是模型在不同的层(layer)中使用了不同的线性层参数，可以有如下好处：

1. **捕捉不同层次的特征**

   每一层的线性变换使用不同的参数，这允许每一层能够学习和捕捉输入数据的不同特征和模式。低层次的层可能学习到一些基本的模式或局部特征，而更高层次的层则可以组合这些低层特征来学习更抽象、更全局的表示。这种层次化的特征学习方式是深度神经网络的核心优势之一。

2. **增强模型的表达能力**

   使用不同层的参数增加了模型的表达能力。每一层都有自己的权重矩阵，这意味着每一层可以独立地调整和优化其输入的表示方式，从而使得整个模型具有更强的灵活性和适应性，可以处理复杂的输入数据。

3. **防止信息瓶颈**

   如果所有层使用相同的线性变换参数，那么模型在不同层次上所能捕捉到的信息会受到极大限制，可能会形成信息瓶颈，限制模型的性能。不同层使用不同的参数，可以确保每一层都有机会独立地学习和表示输入数据的多样性。

4. **提高训练效果**

   不同层使用不同的参数，可以提高模型的训练效果。不同层的参数可以根据各自的需求进行调整，从而优化整个模型的性能。反之，如果所有层共享参数，可能会导致训练过程中的冲突和不稳定。

5. **支持多头注意力机制**

   在Transformer中，尤其是在多头注意力机制中，不同头的线性变换参数允许每个注意力头关注输入数据的不同部分和不同方面。这样可以让模型在同一层中并行地捕捉到多种不同的特征和关系，进一步增强了模型的能力和表现。





#### 5、嵌入层(Embeddings)与输出层

使用可学习的嵌入层将输入与输出转换为维度为$d_{model}$的向量，使用可学习的线性变换和softmax函数将输出用于预测下一个token的概率。

*注*：在嵌入层，我们将权重乘上因子$\sqrt{d_{model}}$，这可以理解为是对后面除以$\sqrt{d_k}$的缩放操作的对称操作，可以让输入和输出有更相近的数值尺度。这是一种确保不同层之间数值范围一致性的有效方法，有助于整体模型的性能提升。





#### 6、位置编码

在Transformer中，位置编码是一个很重要的机制，它使得Transformer无需受到时序序列不同位置时间的限制，可以并行地进行计算，同时又能获得序列中的位置信息。位置编码的方式有很多种，本文中采用了正余弦函数位置编码：
$$
PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\\PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})
$$
其中pos是位置编号，i是维度编号。这里的波长形成一个从$2\pi$到$10000·2\pi$的等比序列。

如下是位置编码的可视化图像：

<img src="./assets/posemb.png" alt="image-20240606234922067" style="zoom: 50%;" />

作者认为这种位置编码可以让模型很好地学习到相对位置的注意力，因为对于固定的k值，$PE_{pos+k}$可以表示为$PE_{pos}$的线性函数。

==问：如何理解这种位置编码的物理含义？==









### 二、方法论：为什么要使用注意力机制？

